---
title: 'Agile Teams Quick Playbook'
date: '2023-10-30'
lastmod: '2023-10-30'
tags: ['agile', 'mvp', 'playbook']
draft: false
summary: 'Engineering quality into your SDLC by adopting a shift left team mindset can lead to higher quality outcomes with fewer bugs and happier customers'
images: ['/static/images/agilemvp.png']
---

# Introduction

We've all heard of Agile software development, but what does it really mean? How do you know if you're doing it right? How do you know if you're doing it wrong? How do you know if you're doing it at all?

By the end of this article, you should have a better understanding of what an Agile team looks like and some guidance on some best practices.

If you haven't already read these, give them a read:

- [Agile Manifesto](https://agilemanifesto.org/)
- [12 Principles](https://agilemanifesto.org/principles.html)
- [Modern Agile](https://modernagile.org/)

Let's get started...

# MVP - Minimum Viable Product:

There are hundreds of similar, but different definitions of MVP. Here is one more to add to the pile:

> The smallest deliverable that solves a problem or adds value

That is a pretty broad definition, but part of agile is leaving things open to interpretation and allowing teams to self-organize to meet the needs of the customer and themselves.

Building on that definition, we want to make sure we are _incrementally_ building on top of whatever we're shipping. Why?

Agile software development relies on continuous and incremental improvement, gathering feedback along the way. We do this so we can ensure we're calibrating our direction as much as possible.

![Agile MVP](/static/images/agilemvp.png)

Another core tenet of agile is being able to abandon ship or delete features at any time. Not everything we build will solve the problem we attempted to tackle. Sometimes things just don't stick. That's OK! These are good outcomes. And if we practiced good, incremental software delivery we know that we spent just enough time (and not more!) to come to a conculsion supported by real customer data.

If you find yourself stuck, features are taking too long to ship, or a high degree of bugs are being introduced, use the following prompt in your next grooming or planning session to help refocus your team:

> What is the smallest bit of product we can deliver that adds value

# Grooming and Planning

This phase is the one which requires the most effort to 'get it right', but will yield the highest reward if successful. If this phase is shortcut or unattended to, be ready for a world of hurt.

Planning and Grooming are the steps that grease the gears for the rest of the SDLC. If you don't have clear, well defined pieces of work you leave yourself exposed to scope creep, missed requirements, and bugs.

When teams have an understanding of the risks of the domain they're working in and the business need is clear and well defined, engineers have the best chance to develop bug free software that is secure, scalable, reliable, and well tested.

If you're struggling to write good stories, cards, tickets, or whatever you call them, here's some prompts and guidelines for what a good story should contain:

- On the whole, the ticket should be understandable by anyone in your ogananization or business line. This means eliminating as much technical jargon as possible. You should have clear and concise descriptions. Acronyms are well understood otherwise avoided.
- Each ticket should have a user story. This is the building block for the rest of the ticket: "As a [user type], I want to [do something] so that [I can achieve some goal]." If you can't write a user story, you don't have a clear understanding of the problem you're trying to solve.
- If you're shipping features with UI components, attach Mock-ups or screenshots of what you're trying to build. This will help eliminate any visual design assumptions. If you can't make sure there is an acceptance critera or requirement to "Pair with UX" during the development process. Pairing with UX in the moment of development is a great way to iterate quickly on design and layout, rather than discovering the UI is faulty later on during the software delivery cycle.
- Attach relevant data warehouse or analytics queries
- Attach software documentation (3rd party or Internal), or API Docs
- Attach customer feedback, support tickets, or recorded customer calls so the team can fill in any gaps or resolve ambiguities
- Remove or qualify as many assumptions as possible. Assumptions can lead to divergence from the goal and can introduce bugs or missed requirements.
- Identify potential risks (internal and external) to product, team, customer, code, 3rd parties, etc
- Identify testing needs. Can the other developers test the ticket themselves? Does it need a specific Quality Engineer to test the ticket. More on this in [TODO: this blog post]
- Identify any code or inter/intra app dependencies. Does it need to be forward/backward compatible? What are the release and/or rollback stragegies if any?
- Idenitfy post release monitoring, metrics, KPIs, alerting, experiments, etc.

Remember to keep stories small and incremental. A little bit of delivered value today can make a big difference.

# Acceptance criteria

From all of the preparation work done in Planning and the beginning of Grooming, ACs (requirements, etc) distill all the information from above down into specific units of work. These points should be concise and clear and tie back to the business value. Where possible, each of these ACs should correspond to both:

- a code change
- an automated test

Even if your team doesn't practice TDD (Test Driven Development), you should still be writing automated tests to cover your code. Pairing app code with automation code, and treating automation code as a first class priority, will help your team move quickly and safely. Automation code is insurance to prevent future pain.

Planning and Grooming sessions can be long and tedious, but they are arguably the most important part of the SDLC. Because there is so much information to cover, it is best to follow this rule of thumb:

> If it's obvious, write it down

People won't remember what the team verbally agreed to a few days prior to picking up a ticket. The agreements are usually 'obvious' and 'common sense' at the time, but there is a laundry list of things that people are keeping track of in their head. Include the obvious units of work to be done as ACs so they aren't overlooked or forgotten. A note is easily buried in a description of a ticket. An AC is a specific call out, and very easy to check against.

Some tips for good Acceptance Criteria:

NOT a “QA Checklist”

Should all be checked off before code review

Should all be manually tested by developer prior to code review

# Code Review, Testing & Release phase

Drive cards through to release

Don’t let things get “stuck” in this phase

Have a well defined and understood process for when something can transition from Code Review to Testing, and who will perform the testing (if applicable)

Testing is not the first time a story is being tested, this phase should be additional testing gestures to supplement and extend previous testing/quality assurance motions.

You’re not re-verifying Acceptance criteria here, you’re building on top of those! (because the ACs should already be covered by automated tests)

Execute testing strategy identified in Grooming

Post release, circle back onto the release monitoring and metrics you established in grooming

This is a continuous process not a 1-time check-up

# Meeting hygiene

Is the scheduled meeting still valuable, and/or still meeting the original purpose of the meeting

Does the meeting often extend beyond the scope/purpose of the meeting? Are you grooming in standup.. etc?

Keep conversations focused. It is easy to tangent and waste significant time discussing adjacent issues that aren’t blockers.

Identify someone as the meeting/time steward. They have the power to interrupt when they see the team is getting off base, psychological safety is eroding, or other similar issues

Do you have too many meetings? There is a price to pay for context switching (approx 25 mins to refocus after an interruptions)

Could the meeting be an email or slack message/thread?

# Retrospectives

Taking time to reflect is important

Be open minded, honest, empathetic, and professional

Avoid making things personal. Focus on the impact / problem, not the person

Use something structured

Don’t forget to celebrate wins and your teammates

Assign someone to run the retro (timing, organization, action items and follow up). If you can’t find someone on your team, ask around. There are several people in the org who know how to run an effective retrospective. Typically those that run retros don’t participate directly so they can remain objective.

# In Summary

I hope these guidelines can help you in your team's efforts to deliver higher quality software with reduced effort
